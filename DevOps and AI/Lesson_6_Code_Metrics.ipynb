{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Code Metrics"
      ],
      "metadata": {
        "id": "PFxT-i5JEV-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrvFNG_IEUJp",
        "outputId": "a8759a55-5b20-4095-f0a3-62fc33b83ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cnn_mnist.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile cnn_mnist.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, utils, datasets\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"Build and compile a convolutional neural network model.\"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def preprocess_data(train_images, train_labels, test_images, test_labels):\n",
        "    \"\"\"Preprocess MNIST data for training and testing.\"\"\"\n",
        "    # Reshape and scale pixel values to range [0, 1]\n",
        "    train_images = train_images.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "    test_images = test_images.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "def train_model(model, train_images, train_labels, epochs=5, batch_size=32):\n",
        "    \"\"\"Train the convolutional neural network model.\"\"\"\n",
        "    history = model.fit(train_images, train_labels,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_split=0.1)\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, test_images, test_labels):\n",
        "    \"\"\"Evaluate the trained model on test data.\"\"\"\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    return test_accuracy\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to build, train, and evaluate the CNN model.\"\"\"\n",
        "    # Load MNIST dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "    # Preprocess data\n",
        "    train_images, train_labels, test_images, test_labels = preprocess_data(train_images, train_labels, test_images, test_labels)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = build_model()\n",
        "\n",
        "    # Train the model\n",
        "    history = train_model(model, train_images, train_labels)\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    evaluate_model(model, test_images, test_labels)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lines of Code (LOC):"
      ],
      "metadata": {
        "id": "xbHDvG06EpVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install radon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbxgeL6TEuRa",
        "outputId": "0f20c4dc-9d17-42c9-9991-41c73c5c18cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting radon\n",
            "  Downloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mando<0.8,>=0.6 (from radon)\n",
            "  Downloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting colorama>=0.4.1 (from radon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
            "Installing collected packages: mando, colorama, radon\n",
            "Successfully installed colorama-0.4.6 mando-0.7.1 radon-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from radon.complexity import cc_visit\n",
        "from radon.raw import analyze\n",
        "\n",
        "with open('cnn_mnist.py', 'r') as f:\n",
        "    file_content = f.read()\n",
        "\n",
        "raw_metrics = analyze(file_content)\n",
        "complexity_results = cc_visit(file_content)"
      ],
      "metadata": {
        "id": "HTKeA_XFEnUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Lines of Code (LOC): {raw_metrics.loc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4o0f1UaFIha",
        "outputId": "cf4d6104-172e-44bd-b6cb-01507dfcc914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines of Code (LOC): 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cyclomatic Complexity:"
      ],
      "metadata": {
        "id": "gi1YRlsHFcKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print function-wise Cyclomatic Complexity\n",
        "print(\"Function-wise Cyclomatic Complexity:\")\n",
        "for result in complexity_results:\n",
        "    print(f\"Function: {result.name}, Complexity: {result.complexity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAPWH3sLFJgS",
        "outputId": "353188cc-8f20-4101-d7ea-d1ba5d3c4e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function-wise Cyclomatic Complexity:\n",
            "Function: build_model, Complexity: 1\n",
            "Function: preprocess_data, Complexity: 1\n",
            "Function: train_model, Complexity: 1\n",
            "Function: evaluate_model, Complexity: 1\n",
            "Function: main, Complexity: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Maintainability Index (MI):"
      ],
      "metadata": {
        "id": "yDB5Pa70Fg_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from radon.metrics import mi_visit\n",
        "\n",
        "# Calculate the Maintainability Index (MI)\n",
        "maintainability_index = mi_visit(file_content, multi=False)\n",
        "\n",
        "# Print the Maintainability Index (MI)\n",
        "print(f\"Maintainability Index (MI): {maintainability_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFQMOr4tFMja",
        "outputId": "12e7e2a6-901a-4da2-c308-93a67e3a6d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maintainability Index (MI): 77.43399704628632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Smells:"
      ],
      "metadata": {
        "id": "qmeFSh9GFaH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install flake8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSthGTJQFZxc",
        "outputId": "bf814922-4375-4957-dc9b-f790de6696d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flake8\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0 (from flake8)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyflakes, pycodestyle, mccabe, flake8\n",
            "Successfully installed flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!flake8 cnn_mnist.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06LRSwMKFtCC",
        "outputId": "e4116011-6b07-4f3c-b0ed-ce157666ec9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m1\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mF401\u001b[m 'tensorflow as tf' imported but unused\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m2\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mF401\u001b[m 'tensorflow.keras.utils' imported but unused\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m4\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE302\u001b[m expected 2 blank lines, found 1\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m21\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE302\u001b[m expected 2 blank lines, found 1\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m24\u001b[36m:\u001b[m80\u001b[36m:\u001b[m \u001b[1m\u001b[31mE501\u001b[m line too long (82 > 79 characters)\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m25\u001b[36m:\u001b[m80\u001b[36m:\u001b[m \u001b[1m\u001b[31mE501\u001b[m line too long (80 > 79 characters)\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m28\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE302\u001b[m expected 2 blank lines, found 1\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m36\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE302\u001b[m expected 2 blank lines, found 1\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m42\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE302\u001b[m expected 2 blank lines, found 1\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m45\u001b[36m:\u001b[m80\u001b[36m:\u001b[m \u001b[1m\u001b[31mE501\u001b[m line too long (89 > 79 characters)\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m48\u001b[36m:\u001b[m80\u001b[36m:\u001b[m \u001b[1m\u001b[31mE501\u001b[m line too long (128 > 79 characters)\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m54\u001b[36m:\u001b[m5\u001b[36m:\u001b[m \u001b[1m\u001b[31mF841\u001b[m local variable 'history' is assigned to but never used\n",
            "\u001b[1mcnn_mnist.py\u001b[m\u001b[36m:\u001b[m59\u001b[36m:\u001b[m1\u001b[36m:\u001b[m \u001b[1m\u001b[31mE305\u001b[m expected 2 blank lines after class or function definition, found 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Coverage"
      ],
      "metadata": {
        "id": "u7iw5aVIFs5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install coverage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LaCKgMfGVfq",
        "outputId": "605835f4-6ff1-4995-9fb2-7e361926629f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coverage\n",
            "  Downloading coverage-7.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: coverage\n",
            "Successfully installed coverage-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ml_model.py\n",
        "# ml_model.py\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load and preprocess the Iris dataset.\"\"\"\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def train_logistic_regression(X_train, y_train):\n",
        "    \"\"\"Train a logistic regression model.\"\"\"\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"Evaluate the trained model on test data.\"\"\"\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to load data, train the model, and evaluate.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = load_data()\n",
        "    model = train_logistic_regression(X_train, y_train)\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALXZhmTUGo76",
        "outputId": "fa8adffc-52fd-4f24-fd64-941c5a01bd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ml_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_ml_model.py\n",
        "# test_ml_model.py\n",
        "import pytest\n",
        "import numpy as np\n",
        "from ml_model import train_logistic_regression, evaluate_model\n",
        "\n",
        "@pytest.fixture\n",
        "def mock_data():\n",
        "    X_train = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "    y_train = np.array([0, 1, 0, 1])  # Two classes: 0 and 1\n",
        "    return X_train, y_train\n",
        "\n",
        "def test_train_logistic_regression(mock_data):\n",
        "    X_train, y_train = mock_data\n",
        "    model = train_logistic_regression(X_train, y_train)\n",
        "    assert model is not None\n",
        "    assert hasattr(model, 'predict')\n",
        "\n",
        "def test_evaluate_model(mock_data):\n",
        "    X_test = np.array([[1, 2, 3], [4, 5, 6]])  # Test data with samples from both classes\n",
        "    y_test = np.array([0, 1])  # Corresponding true labels for the test data\n",
        "    model = train_logistic_regression(mock_data[0], mock_data[1])  # Train the model with mock data\n",
        "    accuracy = evaluate_model(model, X_test, y_test)\n",
        "    assert accuracy == 0.5  # Expecting 100% accuracy for this simple test case\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UpoBVOnHQDb",
        "outputId": "0212dbb0-b18c-4935-f51d-b92e3ebc89f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_ml_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!coverage run -m pytest test_ml_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPEq49cUIAtq",
        "outputId": "fe44c40a-9daf-4894-d24b-c780858f3def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 2 items                                                                                  \u001b[0m\n",
            "\n",
            "test_ml_model.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                          [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.99s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependency Analysis"
      ],
      "metadata": {
        "id": "YmBnw0hAIwbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW3kXLgoKQBq",
        "outputId": "209c520c-916d-4553-a9db-f76ce28a7ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dependency_analysis.py\n",
        "import importlib\n",
        "import inspect\n",
        "import os\n",
        "from graphviz import Digraph\n",
        "\n",
        "def find_dependencies(filename):\n",
        "    \"\"\"Find direct dependencies (imports and function calls) in a Python file.\"\"\"\n",
        "    dependencies = set()\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('import ') or line.startswith('from '):\n",
        "                module_name = line.split()[1]\n",
        "                if ',' in module_name:\n",
        "                    module_name = module_name.split(',')[0]\n",
        "                dependencies.add(module_name)\n",
        "            elif line.startswith('def '):\n",
        "                function_name = line.split()[1].split('(')[0]\n",
        "                dependencies.add(function_name)\n",
        "    return dependencies\n",
        "\n",
        "def visualize_dependencies(filename, output_file='dependency_graph'):\n",
        "    \"\"\"Visualize dependencies in a Python file as a graph using Graphviz.\"\"\"\n",
        "    dependencies_graph = Digraph(format='png')\n",
        "    visited_functions = set()\n",
        "\n",
        "    def traverse(filename):\n",
        "        if filename in visited_functions:\n",
        "            return\n",
        "        visited_functions.add(filename)\n",
        "        dependencies = find_dependencies(filename)\n",
        "        for dependency in dependencies:\n",
        "            dependencies_graph.edge(filename, dependency)\n",
        "            if os.path.isfile(dependency + '.py'):\n",
        "                traverse(dependency + '.py')\n",
        "\n",
        "    traverse(filename)\n",
        "    dependencies_graph.render(output_file, view=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    script_filename = 'ml_model.py'  # Specify the Python script to analyze\n",
        "    visualize_dependencies(script_filename)"
      ],
      "metadata": {
        "id": "INX16K_qKp5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}